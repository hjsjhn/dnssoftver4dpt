{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics, tree\n",
    "import pandas as pd\n",
    "import collections\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file and preprocess it\n",
    "# - convert result dictionnaries to tuples for determinism\n",
    "# - convert software versions to software names\n",
    "\n",
    "input_data = list()\n",
    "with open(\"../signatures/signatures_all.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        # Load the old entry\n",
    "        entry = json.loads(line)\n",
    "        # Store the processed entry\n",
    "        entry_processed = collections.defaultdict(dict)\n",
    "        for software in entry:\n",
    "            # Keep the software name, excluding the version\n",
    "            if \"bind9\" in software: software_only = \"bind9\"\n",
    "            elif \"knot\" in software: software_only = \"knot-resolver\"\n",
    "            elif \"maradns\" in software: software_only = \"maradns\"\n",
    "            elif \"pdns\" in software: software_only = \"pdns-recursor\"\n",
    "            elif \"technitium\" in software: software_only = \"technitium\"\n",
    "            elif \"unbound\" in software: software_only = \"unbound\"\n",
    "            elif \"windows\" in software: software_only = \"windows-server\"\n",
    "            # Test results are dictionnaries, which is not deterministic\n",
    "            # Instead, we convert them into tuples\n",
    "            for testcase in entry[software]:\n",
    "                testresult = entry[software][testcase]\n",
    "                if \"error\" in testresult:\n",
    "                    testresult_new = tuple(sorted(list(testresult.items())))\n",
    "                elif \"answer\" in testresult:\n",
    "                    testresult_new = tuple(sorted(list(testresult[\"header\"].items()) + list(testresult[\"answer\"].items())))\n",
    "                else:\n",
    "                    testresult_new = tuple(sorted(list(testresult[\"header\"].items())))\n",
    "                entry_processed[software_only][testcase] = testresult_new\n",
    "\n",
    "        input_data.append(dict(entry_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we cannot uniquely identify a piece of software, one signature can correspond to multiple labels\n",
    "# In this case, the classifier will not work properly\n",
    "# So, we need to combine those labels with a pipe (\"|\")\n",
    "\n",
    "signature_labels = collections.defaultdict(list)\n",
    "for entry in input_data:\n",
    "    for software in entry:\n",
    "        signature = tuple((sorted(list(entry[software].items()))))\n",
    "        signature_labels[signature].append(software)\n",
    "\n",
    "input_data_processed = list()\n",
    "for signature in signature_labels:\n",
    "    labels_merged = \"|\".join(set(signature_labels[signature]))\n",
    "    signature_dictionnary = {i[0]:i[1] for i in signature}\n",
    "    for _ in range(len(signature_labels[signature])):\n",
    "        input_data_processed.append({labels_merged:signature_dictionnary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be loaded to a DataFrame\n",
    "\n",
    "# Get all the column names from one of the entries\n",
    "column_names_features = [j for i in input_data_processed[0].values() for j in i]\n",
    "column_names_all = [\"label\"] + column_names_features\n",
    "\n",
    "input_data_flat = list()\n",
    "for entry in input_data_processed:\n",
    "    for software in entry:\n",
    "        entry_flat = list()\n",
    "        for column in column_names_all:\n",
    "            if column == \"label\":\n",
    "                entry_flat.append(software)\n",
    "            else:\n",
    "                entry_flat.append(entry[software][column])\n",
    "        input_data_flat.append(entry_flat)\n",
    "\n",
    "# Load as a data frame\n",
    "df = pd.DataFrame(input_data_flat, columns=column_names_all)\n",
    "# Do the one hot encoding\n",
    "df_one_hot = pd.get_dummies(data=df, columns=column_names_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variables\n",
    "X = df_one_hot.loc[:, df_one_hot.columns != 'label']\n",
    "y = df_one_hot.label\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Get some metrics\n",
    "# In our example, the accuracy is always 0\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our one-hot encoded feature names are too long, we need to try to shorten them\n",
    "features_one_hot = df_one_hot.columns.difference([\"label\"], sort=False).tolist()\n",
    "\n",
    "# Here we remove all the brackets and join by pipes\n",
    "features_short = list()\n",
    "# In this list we only keep testcase names\n",
    "features_testcases = list()\n",
    "for i in features_one_hot:\n",
    "    features_short.append(i.replace(\"'\",\"\").replace(\"), (\",\"|\").replace(\", \",\"-\").replace(\"((\",\"\").replace(\"))\",\"\").replace(\"),)\",\"\"))\n",
    "    features_testcases.append(i[:i.index(\"(\")][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- test_chaos_rd_AA-0|AD-0|ANCOUNT-0|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-QUERY|QDCOUNT-1|QR-1|RA-0|RCODE-REFUSED|RD-1|TC-0 <= 0.50\n",
      "|   |--- test_norec_AA-0|AD-0|ANCOUNT-0|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-QUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-0|TC-0 <= 0.50\n",
      "|   |   |--- test_31_172_AA-1|AD-0|ANCOUNT-0|ARCOUNT-1|CD-0|NSCOUNT-1|Opcode-QUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-1|TC-0 <= 0.50\n",
      "|   |   |   |--- test_norec_error-Timeout <= 0.50\n",
      "|   |   |   |   |--- test_iquery_AA-0|AD-0|ANCOUNT-3|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-IQUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-1|TC-0 <= 0.50\n",
      "|   |   |   |   |   |--- test_chaos_rd_error-Timeout <= 0.50\n",
      "|   |   |   |   |   |   |--- class: technitium\n",
      "|   |   |   |   |   |--- test_chaos_rd_error-Timeout >  0.50\n",
      "|   |   |   |   |   |   |--- class: windows-server\n",
      "|   |   |   |   |--- test_iquery_AA-0|AD-0|ANCOUNT-3|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-IQUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-1|TC-0 >  0.50\n",
      "|   |   |   |   |   |--- class: knot-resolver\n",
      "|   |   |   |--- test_norec_error-Timeout >  0.50\n",
      "|   |   |   |   |--- class: maradns\n",
      "|   |   |--- test_31_172_AA-1|AD-0|ANCOUNT-0|ARCOUNT-1|CD-0|NSCOUNT-1|Opcode-QUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-1|TC-0 >  0.50\n",
      "|   |   |   |--- class: unbound\n",
      "|   |--- test_norec_AA-0|AD-0|ANCOUNT-0|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-QUERY|QDCOUNT-1|QR-1|RA-1|RCODE-NOERROR|RD-0|TC-0 >  0.50\n",
      "|   |   |--- class: pdns-recursor\n",
      "|--- test_chaos_rd_AA-0|AD-0|ANCOUNT-0|ARCOUNT-0|CD-0|NSCOUNT-0|Opcode-QUERY|QDCOUNT-1|QR-1|RA-0|RCODE-REFUSED|RD-1|TC-0 >  0.50\n",
      "|   |--- class: bind9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the tree in a text form with feature names in a short format\n",
    "text_representation = tree.export_text(clf,feature_names=features_short)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- test_chaos_rd <= 0.50\n",
      "|   |--- test_norec <= 0.50\n",
      "|   |   |--- test_31_172 <= 0.50\n",
      "|   |   |   |--- test_norec <= 0.50\n",
      "|   |   |   |   |--- test_iquery <= 0.50\n",
      "|   |   |   |   |   |--- test_chaos_rd <= 0.50\n",
      "|   |   |   |   |   |   |--- class: technitium\n",
      "|   |   |   |   |   |--- test_chaos_rd >  0.50\n",
      "|   |   |   |   |   |   |--- class: windows-server\n",
      "|   |   |   |   |--- test_iquery >  0.50\n",
      "|   |   |   |   |   |--- class: knot-resolver\n",
      "|   |   |   |--- test_norec >  0.50\n",
      "|   |   |   |   |--- class: maradns\n",
      "|   |   |--- test_31_172 >  0.50\n",
      "|   |   |   |--- class: unbound\n",
      "|   |--- test_norec >  0.50\n",
      "|   |   |--- class: pdns-recursor\n",
      "|--- test_chaos_rd >  0.50\n",
      "|   |--- class: bind9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the tree in a text form with feature names as testcases\n",
    "text_representation = tree.export_text(clf,feature_names=features_testcases)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of features: 56\n",
      "  Important features: 6\n",
      "  Not important features: 50\n",
      "---\n",
      "The total number of testcases: 10\n",
      "  Important testcases: 4 (test_iquery, test_31_172, test_norec, test_chaos_rd)\n",
      "  Not important testcases: 6 (test_home_arpa, test_zero_ttl, test_is_response, test_baseline, test_tc, test_edns0)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the feature importance, i.e. which ones were used to build the tree, and which ones not\n",
    "feature_importances = pd.DataFrame(data=clf.feature_importances_,columns=[\"importance\"],index=X_train.columns)\n",
    "\n",
    "print(f\"The total number of features: {feature_importances.shape[0]}\")\n",
    "print(f\"  Important features: {feature_importances[feature_importances['importance'] != 0].shape[0]}\")\n",
    "print(f\"  Not important features: {feature_importances[feature_importances['importance'] == 0].shape[0]}\")\n",
    "\n",
    "# Now we aggregate by the testcase names\n",
    "testcases_all = set(i[:i.index(\"(\")][:-1] for i in feature_importances.index.to_list())\n",
    "testcases_important = set(i[:i.index(\"(\")][:-1] for i in feature_importances[feature_importances['importance'] != 0].index.to_list())\n",
    "testcases_not_important_all = set(i[:i.index(\"(\")][:-1] for i in feature_importances[feature_importances['importance'] == 0].index.to_list())\n",
    "testcases_not_important_unique = testcases_all - testcases_important\n",
    "\n",
    "print(\"---\")\n",
    "print(f\"The total number of testcases: {len(testcases_all)}\")\n",
    "print(f\"  Important testcases: {len(testcases_important)} ({', '.join(testcases_important)})\")\n",
    "print(f\"  Not important testcases: {len(testcases_not_important_unique)} ({', '.join(testcases_not_important_unique)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
