{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics, tree\n",
    "import pandas as pd\n",
    "import collections\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file and preprocess it\n",
    "# - convert result dictionnaries to tuples for determinism\n",
    "# - convert software versions to software names\n",
    "\n",
    "input_data = list()\n",
    "\n",
    "with open(\"../signatures/signatures_all.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        # Load the entry\n",
    "        entry = json.loads(line)\n",
    "        for software in entry:\n",
    "            # Keep the software name\n",
    "            software_name = software.split(\"-\")[0]\n",
    "            # Go over each query round\n",
    "            for round in entry[software]:\n",
    "                # Store the processed entry\n",
    "                round_processed = collections.defaultdict(dict)\n",
    "                for testcase in entry[software][round]:\n",
    "                    # Test results are dictionnaries, which is not deterministic\n",
    "                    testresult = entry[software][round][testcase]\n",
    "                    # Instead, we convert them into tuples\n",
    "                    testresult_new = tuple(sorted(list(testresult.items())))\n",
    "                    # Populate a dictionnary with all the tests for one round\n",
    "                    round_processed[software_name][testcase] = testresult_new\n",
    "                # Update the global dictionnary with all the input data\n",
    "                input_data.append(dict(round_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we cannot uniquely identify a piece of software, one signature can correspond to multiple labels\n",
    "# In this case, the classifier will not work properly\n",
    "# So, we need to combine those labels with a pipe (\"|\")\n",
    "\n",
    "signature_labels = collections.defaultdict(list)\n",
    "for entry in input_data:\n",
    "    for software in entry:\n",
    "        signature = tuple(sorted(list(entry[software].items())))\n",
    "        signature_labels[signature].append(software)\n",
    "\n",
    "input_data_processed = list()\n",
    "for signature in signature_labels:\n",
    "    labels_merged = \"|\".join(tuple(sorted(set(signature_labels[signature]))))\n",
    "    signature_dictionnary = {i[0]:i[1] for i in signature}\n",
    "    for _ in range(len(signature_labels[signature])):\n",
    "        input_data_processed.append({labels_merged:signature_dictionnary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be loaded to a DataFrame\n",
    "\n",
    "# Get all the column names from one of the entries\n",
    "column_names_features = [j for i in input_data_processed[0].values() for j in i]\n",
    "column_names_all = [\"label\"] + column_names_features\n",
    "\n",
    "input_data_flat = list()\n",
    "for entry in input_data_processed:\n",
    "    for software in entry:\n",
    "        entry_flat = list()\n",
    "        for column in column_names_all:\n",
    "            if column == \"label\":\n",
    "                entry_flat.append(software)\n",
    "            else:\n",
    "                entry_flat.append(entry[software][column])\n",
    "        input_data_flat.append(entry_flat)\n",
    "\n",
    "input_data_flat = input_data_flat * 2\n",
    "\n",
    "# Load as a data frame\n",
    "df = pd.DataFrame(input_data_flat, columns=column_names_all)\n",
    "# Do the one hot encoding\n",
    "df_one_hot = pd.get_dummies(data=df, columns=column_names_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variables\n",
    "X = df_one_hot.loc[:, df_one_hot.columns != 'label']\n",
    "y = df_one_hot.label\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Get some metrics\n",
    "# In our example, the accuracy is always 0\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our one-hot encoded feature names are too long, we need to try to shorten them\n",
    "features_one_hot = df_one_hot.columns.difference([\"label\"], sort=False).tolist()\n",
    "\n",
    "# Here we remove all the brackets and join by pipes\n",
    "features_short = list()\n",
    "# In this list we only keep testcase names\n",
    "features_testcases = list()\n",
    "for i in features_one_hot:\n",
    "    features_short.append(i.replace(\"'\",\"\").replace(\"), (\",\"_\").replace(\", \",\"-\").replace(\"_((\",\"---\").replace(\"))\",\"\").replace(\"),)\",\"\"))\n",
    "    features_testcases.append(i[:i.index(\"(\")][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- baseline_A_HS_IQUERY_TC_RA---AA-0_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-IQUERY_QDCOUNT-0_QR-1_RA-0_RCODE-NOTIMP_RD-0_TC-0 <= 0.50\n",
      "|   |--- baseline_A_ANY_QUERY_AA---AA-0_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-QUERY_QDCOUNT-1_QR-1_RA-1_RCODE-NOERROR_RD-0_TC-0 <= 0.50\n",
      "|   |   |--- baseline_A_NONE_QUERY_AA_TC---AA-1_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-QUERY_QDCOUNT-1_QR-1_RA-0_RCODE-FORMERR_RD-0_TC-0 <= 0.50\n",
      "|   |   |   |--- baseline_A_IN_QUERY_AA---error-Timeout after 5 seconds <= 0.50\n",
      "|   |   |   |   |--- baseline_A_IN_STATUS_AA_TC_RD_RA---AA-0_ANCOUNT-3_ARCOUNT-0_NSCOUNT-0_Opcode-STATUS_QDCOUNT-1_QR-1_RA-1_RCODE-NOERROR_RD-1_TC-0 <= 0.50\n",
      "|   |   |   |   |   |--- baseline_A_RESERVED0_IQUERY_TC_RD_RA---error-Timeout after 5 seconds <= 0.50\n",
      "|   |   |   |   |   |   |--- class: technitium\n",
      "|   |   |   |   |   |--- baseline_A_RESERVED0_IQUERY_TC_RD_RA---error-Timeout after 5 seconds >  0.50\n",
      "|   |   |   |   |   |   |--- class: windows\n",
      "|   |   |   |   |--- baseline_A_IN_STATUS_AA_TC_RD_RA---AA-0_ANCOUNT-3_ARCOUNT-0_NSCOUNT-0_Opcode-STATUS_QDCOUNT-1_QR-1_RA-1_RCODE-NOERROR_RD-1_TC-0 >  0.50\n",
      "|   |   |   |   |   |--- class: knot\n",
      "|   |   |   |--- baseline_A_IN_QUERY_AA---error-Timeout after 5 seconds >  0.50\n",
      "|   |   |   |   |--- class: maradns\n",
      "|   |   |--- baseline_A_NONE_QUERY_AA_TC---AA-1_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-QUERY_QDCOUNT-1_QR-1_RA-0_RCODE-FORMERR_RD-0_TC-0 >  0.50\n",
      "|   |   |   |--- class: unbound\n",
      "|   |--- baseline_A_ANY_QUERY_AA---AA-0_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-QUERY_QDCOUNT-1_QR-1_RA-1_RCODE-NOERROR_RD-0_TC-0 >  0.50\n",
      "|   |   |--- class: pdns\n",
      "|--- baseline_A_HS_IQUERY_TC_RA---AA-0_ANCOUNT-0_ARCOUNT-0_NSCOUNT-0_Opcode-IQUERY_QDCOUNT-0_QR-1_RA-0_RCODE-NOTIMP_RD-0_TC-0 >  0.50\n",
      "|   |--- class: bind9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the tree in a text form with feature names in a short format\n",
    "text_representation = tree.export_text(clf,feature_names=features_short, max_depth=len(features_one_hot))\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- baseline_A_HS_IQUERY_TC_RA <= 0.50\n",
      "|   |--- baseline_A_ANY_QUERY_AA <= 0.50\n",
      "|   |   |--- baseline_A_NONE_QUERY_AA_TC <= 0.50\n",
      "|   |   |   |--- baseline_A_IN_QUERY_AA <= 0.50\n",
      "|   |   |   |   |--- baseline_A_IN_STATUS_AA_TC_RD_RA <= 0.50\n",
      "|   |   |   |   |   |--- baseline_A_RESERVED0_IQUERY_TC_RD_RA <= 0.50\n",
      "|   |   |   |   |   |   |--- class: technitium\n",
      "|   |   |   |   |   |--- baseline_A_RESERVED0_IQUERY_TC_RD_RA >  0.50\n",
      "|   |   |   |   |   |   |--- class: windows\n",
      "|   |   |   |   |--- baseline_A_IN_STATUS_AA_TC_RD_RA >  0.50\n",
      "|   |   |   |   |   |--- class: knot\n",
      "|   |   |   |--- baseline_A_IN_QUERY_AA >  0.50\n",
      "|   |   |   |   |--- class: maradns\n",
      "|   |   |--- baseline_A_NONE_QUERY_AA_TC >  0.50\n",
      "|   |   |   |--- class: unbound\n",
      "|   |--- baseline_A_ANY_QUERY_AA >  0.50\n",
      "|   |   |--- class: pdns\n",
      "|--- baseline_A_HS_IQUERY_TC_RA >  0.50\n",
      "|   |--- class: bind9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the tree in a text form with feature names as testcases\n",
    "text_representation = tree.export_text(clf,feature_names=features_testcases, max_depth=len(features_one_hot))\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of features: 3564\n",
      "  Important features: 6\n",
      "  Not important features: 3558\n",
      "---\n",
      "The total number of testcases: 768\n",
      "  Important testcases: 6\n",
      "  Not important testcases: 762\n",
      "---\n",
      "All versions: 7\n",
      "    Individual versions: 7\n"
     ]
    }
   ],
   "source": [
    "# Analyze the feature importance, i.e. which ones were used to build the tree, and which ones not\n",
    "feature_importances = pd.DataFrame(data=clf.feature_importances_,columns=[\"importance\"],index=X_train.columns)\n",
    "\n",
    "print(f\"The total number of features: {feature_importances.shape[0]}\")\n",
    "print(f\"  Important features: {feature_importances[feature_importances['importance'] != 0].shape[0]}\")\n",
    "print(f\"  Not important features: {feature_importances[feature_importances['importance'] == 0].shape[0]}\")\n",
    "\n",
    "# Now we aggregate by the testcase names\n",
    "testcases_all = set(i.split(\"_((\")[0] for i in feature_importances.index.to_list())\n",
    "testcases_important = set(i.split(\"_((\")[0] for i in feature_importances[feature_importances['importance'] != 0].index.to_list())\n",
    "testcases_not_important_all = set(i.split(\"_((\")[0] for i in feature_importances[feature_importances['importance'] == 0].index.to_list())\n",
    "testcases_not_important_unique = testcases_all - testcases_important\n",
    "\n",
    "print(\"---\")\n",
    "print(f\"The total number of testcases: {len(testcases_all)}\")\n",
    "print(f\"  Important testcases: {len(testcases_important)}\")\n",
    "print(f\"  Not important testcases: {len(testcases_not_important_unique)}\")\n",
    "\n",
    "# Also check how many unique versions we got out of all:\n",
    "# versions_all = df_one_hot\n",
    "labels_all = set(df_one_hot[\"label\"].to_list())\n",
    "labels_individual = [i for i in labels_all if \"|\" not in i]\n",
    "versions_all = set(j for i in labels_all for j in i.split(\"|\"))\n",
    "\n",
    "print(\"---\")\n",
    "print(f\"All versions: {len(versions_all)}\")\n",
    "print(f\"    Individual versions: {len(labels_individual)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
